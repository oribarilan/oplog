{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Home","text":"<p> Easy-to-use context-rich Python logging library. </p> <p> </p> <p>Full documentation: oribarilan.github.io/oplog.</p> <p>Source code: github.com/oribarilan/oplog.</p>"},{"location":"#what-is-oplog","title":"What is oplog?","text":"<p>Warning</p> <p>oplog is currently in beta. At this point, we expect the API to be stable and core functionality to be working as expected. However, there are still some features that you may find missing. If you have any feedback, please open an issue.</p> <p>oplog is a modern logging library for Python applications. oplog offers a different paradigm for logging, which is based on the concept of logging operations. Instead of creating a \"log-book\", which is a long scroll of text messages, oplog is about logging operations with rich data.</p>"},{"location":"#key-features","title":"Key features","text":"<ol> <li>Object Oriented: Intuitive API, easy to use and extend.</li> <li>Modern &amp; Scalable: Unlike log messages, oplog is scaleable. Ingesting oplogs to a columnar database allows you to query, analyze and monitor your app in a modern and performant way.</li> <li>Standardized: No more mess and inconsistency across your logs. oplog creates a standard for how logs should be written across your code base. Clean code, clean logs.</li> <li>Production Ready: Easily create dashboards and monitors on top of logged data.</li> <li>Lightweight: oplog is a layer on top of the standard Python logging library. It is easy to integrate and use.</li> <li>Minimal: While oplog is rich with metadata, you only log what you need. Creating smaller and more efficient logs.</li> </ol>"},{"location":"alternatives/","title":"Logging Libraries","text":""},{"location":"alternatives/#why-oplog","title":"Why oplog?","text":"<p>oplog is a minimal and modern logging library for Python applications, which offers a different paradigm for logging, which is based on the concept of logging operations. Instead of creating a \"log-book\", which is a long scroll of text messages, oplog is about logging operations with rich structured data. This allows you to query, analyze and monitor your app in a modern and performant way. oplog focuses on simple and minimal API, and is built on top of the standard Python logging library - to make it easy to integrate and use, even for existing projects.</p>"},{"location":"alternatives/#not-sure-oplog-is-for-you-there-are-alternatives","title":"Not sure oplog is for you? There are alternatives!","text":"<p>oplog is not alone. There are some other great logging libraries out there that you can consider.</p> <p>All content below is my own personal impression and opinion, which is meant to provide some guidance on picking the right logging library for you. It is not meant to be a comprehensive review of the libraries, nor a critic. Please try them out yourself and see what works best for your project.</p> Library Loggin Paradigm API Promise Migration Feature-set oplog Operation-based + Key-Value Standard Clean Code + Structure Easy Working on it \ud83e\udd13 loguru Message-based Custom API Minimality Hard Very Rich structlog Message-based + Key-Value Custom Structure Med Rich logbook Message-based Standard-ish Performance Hard Ok"},{"location":"contribution/active_backlog/","title":"Active Backlog","text":"<p>This page lists the backlog from oplog owners. If you have a feature request, please open an issue, as described in Contribution.</p>"},{"location":"contribution/active_backlog/#code","title":"Code","text":"<ul> <li>[ ] Revisit the timing mechanism (performance timer vs clock timer)</li> <li>[ ] Support custom inheritors</li> <li>[x] CLI usage: progress bars</li> <li>[ ] CLI usage: spinner</li> </ul>"},{"location":"contribution/active_backlog/#devops-prioritized","title":"DevOps (prioritized)","text":"<ul> <li>[x] CI/CD (Github Actions) with all checks</li> <li>[x] Justfile</li> <li>[ ] doc strings to Mkdocs: https://github.com/mkdocstrings/mkdocstrings</li> <li>[ ] doc string enforcement</li> <li>[ ] Poetry</li> <li>[ ] Precommit Hooks</li> <li>[ ] Check push policy vs PR policy</li> <li>[ ] Docker</li> <li>[ ] Dev Container</li> <li>[ ] Coverage % in badge (currently shows pass/fail)</li> <li>[ ] Individual coverage in justfile</li> <li>[ ] Consider more quality checkers (or config for existing one)</li> <li>[ ] Consider more linters (or config for existing one)</li> </ul>"},{"location":"contribution/contribution/","title":"Contribution","text":"<p>Please refer to Code of Conduct for our standards of communication and behavior.</p>"},{"location":"contribution/contribution/#contribute-to-our-bug-reports-feature-requests","title":"Contribute to our Bug Reports &amp; Feature Requests","text":"<ul> <li> <p>Do not open up a GitHub issue if the bug is a security vulnerability, and instead to please contact the owner of the repository directly via email at <code>python_oplog@gmail.com</code>.</p> </li> <li> <p>Ensure the bug was not already reported by searching on GitHub under Issues.</p> </li> <li> <p>If you're unable to find an open issue addressing the problem, open a new one. Be sure to include a title and clear description, and as much relevant information as possible. Issues with minimal code samples (repro) or a failing executable test case demonstrating the expected behavior that is not occurring - will be prioritized.</p> </li> </ul>"},{"location":"contribution/contribution/#contribute-to-the-documentation","title":"Contribute to the Documentation","text":"<p>Our documentation uses MkDocs and the Material for MkDocs theme. Use the following commands to run a local documentation server for documentation contribution:</p> <pre><code>just docs\n</code></pre> <p>or, if you don't have <code>just</code> installed:</p> <p><pre><code>mkdocs serve\n</code></pre> Make sure you open the documentation in your browser as incognito/private mode, otherwise you might see cached versions of the documentation, and experience unexpected behavior.</p>"},{"location":"contribution/contribution/#contribute-to-our-source-code","title":"Contribute to our Source Code","text":"<p>Refer to Development for details on our development environment setup and coding conventions.</p>"},{"location":"contribution/contribution/#fix-a-bug","title":"Fix a Bug","text":"<ul> <li> <p>Open a new GitHub pull request with the fix.</p> </li> <li> <p>Ensure the PR description clearly describes the problem and solution. Include the relevant issue number.</p> </li> <li> <p>Make sure you follow our coding conventions. </p> </li> </ul>"},{"location":"contribution/contribution/#add-a-feature","title":"Add a Feature","text":"<ul> <li> <p>oplog grows by tackling needs and pain of developers. First, report the issue (even if not a bug) as mentioned above.</p> </li> <li> <p>Follow the same steps as for fixing a bug.</p> </li> </ul> <p>\ud83d\udc9a Thanks for supporting oplog! \u29d3</p>"},{"location":"contribution/development/","title":"Development","text":""},{"location":"contribution/development/#environment-setup","title":"Environment Setup","text":"<p>This project was developed by the Author on MacOS, using VS Code as the IDE. The following instructions may vary depending on your environment.</p> <ol> <li>Install the latest version of Python.</li> <li>Install requirements by running <code>pip install -r requirements.txt</code> from the root directory.</li> <li>Install dev requirements by running <code>pip install -r requirements-dev.txt</code> from the root directory.</li> <li>Install Just</li> </ol> <p>Run <code>just test</code> from the root directory to make sure everything is working.</p>"},{"location":"contribution/development/#development_1","title":"Development","text":"<p>We use <code>just</code> as our task runner. To see all available tasks, run <code>just --list</code>. The main command you'll need is <code>just check</code>, which runs tests with coverage check, linting and code quality. If this passes, your code will most likely pass the Pull-Request checks.</p>"},{"location":"contribution/development/#code-coverage","title":"Code Coverage","text":"<p>Code coverage is enforced by <code>coverage</code>. To run the tests and generate a coverage report,  run the following command from the root directory`:</p> <pre><code>just test-coverage\n</code></pre> <p>We have a minimum coverage threshold of 90% of individual file coverage, and overall 95%.</p>"},{"location":"contribution/development/#code-linting","title":"Code Linting","text":"<p>Linting is currently done using <code>ruff</code>. </p> <pre><code>just lint\n</code></pre>"},{"location":"contribution/development/#code-quality","title":"Code Quality","text":"<p>Code quality currently runs just <code>mypy</code>.</p> <pre><code>just quality\n</code></pre>"},{"location":"demos/find_nth_prime/","title":"Find Nth Prime Demo","text":"<p>Application Scenario: CLI Tool</p> <p>Telemetry Form: Progress Bars</p> <p>\ud83d\udea7 Work in progress. Please come back later. \ud83d\udea7</p>"},{"location":"demos/fluent_calculator/","title":"Fluent Calculator","text":"<p>Application Scenario: Logic App (e.g., Worker)</p> <p>Telemetry Form: Structured CSV Telemetry</p> <p>\ud83d\udea7 Work in progress. Please come back later. \ud83d\udea7</p> <p>This demo shows how to use oplog for structured logging. The most common benefit of structured logs is the ability to query them in a performant way, as well as creating dashboards and monitors on top of them. Usually, this is achieved by ingesting the logs into a columnar database, such as AWS CloudWatch, Google BigQuery, Azure Data Explorer, Splunk and more.</p> <p>In these cases, we create JSON object out of every oplog, and ingest it into the database. In the Fluent Calculator example, we demonstrate the same concept but using CSV instead of JSON, for readability purposes.</p> <p>Running the example, will create the following CSV log file:</p> StartTime DurationMS OperationName CorrelationId Result ExceptionType 11/08/2023  22:28:24.0 0 FluentCalculator.init 04a94ba0-ed7d-458a-94f5-0f1dd033fcbd Success None 11/08/2023  22:28:24.0 1000 FluentCalculator.add 04a94ba0-ed7d-458a-94f5-0f1dd033fcbd Success None 11/08/2023  22:28:25.0 1000 FluentCalculator.subtract 04a94ba0-ed7d-458a-94f5-0f1dd033fcbd Success None 11/08/2023  22:28:26.0 1003 FluentCalculator.get_result 04a94ba0-ed7d-458a-94f5-0f1dd033fcbd Success None 11/08/2023  22:28:24.0 3007 first_calc 04a94ba0-ed7d-458a-94f5-0f1dd033fcbd Success None 11/08/2023  22:28:27.0 0 FluentCalculator.init e3305e32-9d79-4ca4-99c2-36af2a905d0e Success None 11/08/2023  22:28:27.0 1004 FluentCalculator.add e3305e32-9d79-4ca4-99c2-36af2a905d0e Success None 11/08/2023  22:28:28.0 1002 FluentCalculator.divide e3305e32-9d79-4ca4-99c2-36af2a905d0e Failure ZeroDivisionError 11/08/2023  22:28:27.0 2008 second_calc e3305e32-9d79-4ca4-99c2-36af2a905d0e Failure ZeroDivisionError <p>Things to note (and love \u2764\ufe0f) about this log file:</p> <ol> <li>Readable: It is human readable, yet, without cumbersome text.</li> <li>Scalable: It fits into columnar databases like a glove.</li> <li>Production Ready: It is easy to query, analyze and monitor, for production scenarios.</li> <li>Easy for Devs: Note the two different correlation IDs, one per calculation. We can correlate all operations that were executed within the failing calculation, for example. Powerful for debugging and investigations.</li> </ol> <p>And much more...</p>"},{"location":"demos/fluent_calculator/#server-demo","title":"Server Demo","text":"<p>Our basic server demo is a simple web server that serves... It is written in FastAPI.</p> <p>Install the dependencies by navigating into the <code>examples/server_demo</code> directory and running:</p> <pre><code>pip install -r requirements.txt\n</code></pre> <p>Then, run the server with:</p> <pre><code>uvicorn main:app --reload\n</code></pre>"},{"location":"demos/tbd/","title":"Server Demo","text":"<p>Application Scenario: Web API (powered by FastAPI)</p> <p>Telemetry Form: Verbose Textual Logs</p> <p>\ud83d\udea7 Work in progress. Please come back later. \ud83d\udea7</p> <p>Our basic server demo is a simple web server that serves... It is written in FastAPI.</p> <p>Install the dependencies by navigating into the <code>examples/server_demo</code> directory and running:</p> <pre><code>pip install -r requirements.txt\n</code></pre> <p>Then, run the server with:</p> <pre><code>uvicorn main:app --reload\n</code></pre>"},{"location":"tutorial/config/","title":"Config","text":"<p><pre><code>Operation.config()\n</code></pre> TBD</p>"},{"location":"tutorial/getting_started/","title":"Getting Started","text":""},{"location":"tutorial/getting_started/#installation","title":"Installation","text":"<p>You can install oplog from PyPI using pip: <pre><code>pip install op-log\n</code></pre></p>"},{"location":"tutorial/getting_started/#first-steps","title":"First Steps","text":""},{"location":"tutorial/getting_started/#setting-up-the-logger","title":"Setting up the logger","text":"<p>oplog naturally extends Python's built-in logger.  To start, create an <code>OperationHandler</code>, and attach to it any  logging handler of your choice. Additionally, you should customize your output log format with a formatter. You can create your own or use a built-in one (such as  <code>VerboseOpLogLineFormatter</code>).</p> Setting up the logger<pre><code>import logging\nfrom oplog import Operated, OperationHandler\nfrom oplog.formatters import VerboseOplogLineFormatter\n\nstream_op_handler = OperationHandler(\n    handler=logging.StreamHandler(), # &lt;-- any logging handler\n    formatter=VerboseOplogLineFormatter(), # &lt;-- custom formatter or built-in ones\n)   \nlogging.basicConfig(level=logging.INFO, handlers=[stream_op_handler])\n\n# using a decorator, for simplicity\n@Operated()\ndef foo():\n    pass\n\nfoo()\n</code></pre> <p>Output: Output<pre><code>2023-08-31 17:31:08.519900 (0ms): [foo.foo / Success]\n</code></pre></p> <p>As you can see, you can use any handler, formatter and filter you want. Oplog does not interfere with them.</p> <ul> <li>Line 6 (highlighted) makes any handler an \"Operation Handler\". If you want to also handle log-book-style logs, you can keep your existing handler (for log message, like <code>logger.info(\"This is a conventional log message\")</code>).</li> <li>Line 7 (highlighted) decides on the log format. It is using a built-in formatter, but you can create your own formatter easily.</li> </ul>"},{"location":"tutorial/getting_started/#using-context-managers","title":"Using Context Managers","text":"<p>For more control, you can use the context manager syntax. This allows, for example, to add custom properties to the operation.</p> Logging operations using the context manager<pre><code>import logging\nfrom oplog import Operation, OperationHandler\nfrom oplog.formatters import VerboseOplogLineFormatter\n\nstream_op_handler = OperationHandler(\n    handler=logging.StreamHandler(), # &lt;-- any logging handler\n    formatter=VerboseOplogLineFormatter(), # &lt;-- custom formatter or built-in ones\n)   \nlogging.basicConfig(level=logging.INFO, handlers=[stream_op_handler])\n\n# using a context manager, for more control\ndef bar():\n    with Operation(name=\"my_operation\") as op:\n        op.add(\"metric\", 5)\n        pass\n\nbar()\n</code></pre> <p>Output: Output<pre><code>2023-08-31 17:41:09.088966 (0ms): [my_operation / Success] {'metric': 5}\n</code></pre></p>"},{"location":"tutorial/operated/","title":"Operated","text":"<p>\ud83d\udea7 Work in progress.</p>"},{"location":"tutorial/operation/","title":"Operation","text":"<p>Operations are the core of the library.  They are used to wrap code blocks, and provide a unified way to log and trace them, with rich context.</p>"},{"location":"tutorial/operation/#basic-usage","title":"Basic Usage","text":"<p>The most basic usage of an operation is to wrap a code block with a <code>with</code> statement:</p> Basic Usage<pre><code>with Operation(name=\"foo\") as op:\n    # do something\n    pass\n</code></pre> <p>This will fire a log record with rich operation metadata, like duration, result, exception, thread name, etc. This operation can be formatted according to your needs (verbose log line, csv, JSON, etc.).    </p> <p>For reference on example formatters, refer to  OplogCsvFormatter  or VerboseOplgLineFormatter.</p> <p>A complete example that will print the operation log record to the stdout, using the verbose formatter:</p> Logging operations using the context manager<pre><code>import logging\nfrom oplog import Operation, OperationHandler\nfrom oplog.formatters import VerboseOplogLineFormatter\n\nstream_op_handler = OperationHandler(\n    handler=logging.StreamHandler(), # &lt;-- any logging handler\n    formatter=VerboseOplogLineFormatter(), # &lt;-- custom formatter or built-in ones\n)   \nlogging.basicConfig(level=logging.INFO, handlers=[stream_op_handler])\n\n# using a context manager, for more control\ndef bar():\n    with Operation(name=\"my_operation\") as op:\n        pass\n\nbar()\n</code></pre>"},{"location":"tutorial/progressable/","title":"Progressable","text":"<p>Progressable operations are operations that can report their progress.  This is useful for long-running operations (e.g., with multiple IO calls or numerous iterations). To make an operation progressable, simply call the <code>progressable()</code> method on the operation. Then, progress is reported using the <code>progress()</code> method.</p>"},{"location":"tutorial/progressable/#progress-bar","title":"Progress Bar","text":"<p>By default, progressable operations also display a progress bar (powered by tqdm),  which can be toggled off using the <code>with_pbar</code> flag (<code>Operation(...).progressable(with_pbar=False)</code>).</p> <p>Nested progressable operations will display nested progress bars nicely, with no additional configuration:</p> <p></p> <p>This is useful for CLI tools, for example.</p> <p>For a CLI example, please refer to the Find Nth Prime example.</p>"},{"location":"tutorial/progressable/#completion-ratio","title":"Completion Ratio","text":"<p>With or without progress bars, progressable operation maintain a <code>completion_ratio</code> property, which can be access from the operation: <code>op.completion_ratio</code> (raises <code>AttributeError</code> if not progressable).</p> <p>Completion ratio property is a float between 0 and 1, which represents the progress of the operation, as reported by <code>iterations</code> argument and <code>op.progress()</code> call. Completed operations will have a completion ratio of 1 (even if no <code>iterations</code> given). In cases where completion ratio is unknown, it will be <code>None</code>  (no iterations given and operation exited before completion - e.g., due to exception).</p>"},{"location":"tutorial/property_groups/","title":"Property Groups","text":""},{"location":"tutorial/property_groups/#meta-properties-operation-metadata","title":"Meta Properties (Operation metadata)","text":"<p>Meta properties are properties that describe the operation itself, such as the operation name, its duration, result (success / failure) etc. They are managed automatically to every operation, and do not require additional care.</p>"},{"location":"tutorial/property_groups/#correlation-id","title":"Correlation ID","text":"<p><code>correlation_id</code> is a special kind of meta property. When investigating issues, developers find themselves needing to correlate between different operations. For example, when a user reports a bug, the developer will want to find all relevant log messages to help investigate and triage the bug. This is where <code>correlation_id</code> comes into play.</p> <p><code>correlation_id</code> is inherited by child operations from their parent operation, within the same execution thread. It can be used to correlate between all nested operations. These nested (or child) operations will have the same correlation ID as the root (or parent) operation.</p> <p>The most common use case for <code>correlation_id</code> is for web server request handling. All operations that were executed within the same request, will be easily correlateable using the <code>correlation_id</code>.</p> Correlation ID example<pre><code>def correlation_id_example():\n    with Operation(\"root_op\") as parent_op:\n        with Operation(\"nested_op\") as child_op:\n            # here, child_op.correlation_id == parent_op.correlation_id\n            # these operations will be easily correlateable in the logs\n            pass\n</code></pre>"},{"location":"tutorial/property_groups/#custom-properties","title":"Custom Properties","text":"<p>Custom properties are properties that are specific to the operation, and are not managed by the library. They are added using the <code>operation.add()</code> method (or similar). Use custom properties to describe a specific instance of the operation.</p> <p>For example, consider this method that fetches items from a storage, but first tries to fetch them from a cache:</p> Item Fetching Example<pre><code>def fetch_items(self):\n    items = self.cache.get('items')\n    if items is None:\n        items = self.storage.get('items')\n        cache.set('items', items)\n    return items\n</code></pre> <p>In this case, we might want to log the cache hit / miss, and the number of items returned. No more need for ambiguous log messages such as \"items retrieved from cache\" or \"items retrieved from storage\".</p> Naive logging of cache hit / miss<pre><code>def fetch_items(self):\n    items = self.cache.get('items')\n    source = 'cache' if items is not None else 'storage'\n    if items is None:\n        items = self.storage.get('items')\n        cache.set('items', items)\n    self.log(f'{len(items_count)} items retrieved from {source}')\n    return items\n</code></pre> Output Example<pre><code>2023-08-09 22:03:31.243611 [INFO]: 3 items retrieved from cache\n</code></pre> Doing it the oplog way<pre><code>def fetch_items(self):\n    with Operation(name=\"foo.get_items_from_storage\") as op:\n        items = self.cache.get('items')\n        is_cache_hit = items is not None\n        op.add('is_cache_hit', is_cache_hit)\n        if not is_cache_hit:\n            items = self.storage.get('items')\n            cache.set('items', items)\n        op.add('items_count', len(items))\n    return items\n</code></pre> Output Example<pre><code>2023-08-09 22:03:31.243611 (0ms): [foo.get_items_from_storage / Success] {'is_cache_hit': True, 'items_count': 3}\n</code></pre> <p>At a first glance, the common log-book style seems easier to read, however, it is not scalable. As the number of operations grows, the number of log messages grows as well, and it becomes harder to find the relevant log message. Developers and analysts will have to either read through many messages that are text-heavy, or, when scaled, will have to extract information from each specific log line (regex, anyone?).</p> <p>Oplog solves this problem by providing a structured way to log operations, and by providing a way to filter and query the log messages. You can still use them to structure a nice log-book if you wish (see <code>VerboseOpLogLineFormatter</code>), but they provide much more flexibility and scalability.</p>"},{"location":"tutorial/property_groups/#global-properties","title":"Global Properties","text":"<p>Global properties are properties that are meant to be set once, and will then be available across all operations in the program lifetime. Use <code>operation.add_global()</code> to add a global property.</p> <pre><code>import logging\nfrom oplog import Operated, Operation\nfrom oplog.formatters import VerboseOplogLineFormatter\n\nlogging.basicConfig(level=logging.INFO, handlers=[logging.StreamHandler()])\nlogging.getLogger().handlers[0].setFormatter(VerboseOplogLineFormatter())\n\nOperation.add_global('project_version', '1.3.0')\nOperation.add_global('build_version', '20230120_001')\n\n@Operated()\ndef foo():\n    pass\n\nfoo()\n</code></pre> Output<pre><code>2023-08-31 22:01:26.458748 (0ms): [foo.foo / Success] {'project_version': '1.3.0', 'build_version': '20230120_001'}\n</code></pre>"},{"location":"tutorial/advanced/serialization/","title":"Operation Serialization","text":"<p>Note</p> <p>In most cases custom serialization is not required. Try using a custom formatter, or the default serialization. </p> <p>While the recommended way to format operation logs is to implement a <code>oplog.formatters.OperationFormatter</code> formatter, in some scenarios, a formatter may not be available for the developer. In such cases, it is common for tools/libs to use the <code>str</code> representation of the operation (<code>%(oplog)s</code>). So, <code>oplog</code> supports this behavior out-of-the-box.</p> <p>A common example is <code>pytest</code>.  <code>pytest</code> uses the <code>str</code> representation of the operation to display the operation in the terminal, most commonly used to display errors (and warning) during tests.</p> <p>You can see an example for the support in <code>pytest</code> in test_fluent_calculator.py</p> <p>Although this is supported, developers may want to override the default string serialization of operations. <code>pytest</code> has limited formatting options (read more about it in pytest: How to manage logging. so <code>oplog</code> provides a way to override the default string serialization of operations.</p> <p>This is done in the <code>config</code> class method, which is commonly called once during logger setup. </p>"},{"location":"tutorial/advanced/serialization/#example","title":"Example","text":"<pre><code>Operation.config(..., serializer=lambda op: f\"{op.name} - {op.status}\")\n</code></pre> <p>You can read more about <code>config</code> in Config.</p>"}]}